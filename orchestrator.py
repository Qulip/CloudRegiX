from typing import Dict, Any, List
from agents import (
    RouterAgent,
    PlannerAgent,
    AnswerAgent,
    ReActExecutorAgent,
    TraceManagerAgent,
)
from tools import ReasoningTraceLogger, PlanRevisionTool, StateManager
import time


class CloudGovernanceOrchestrator:
    """
    í´ë¼ìš°ë“œ ê±°ë²„ë„ŒìŠ¤ AI ì‹œìŠ¤í…œ í•˜ì´ë¸Œë¦¬ë“œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    Plan & Execute + ReAct í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬
    """

    def __init__(self):
        self.router_agent = RouterAgent()
        self.planner_agent = PlannerAgent()
        self.answer_agent = AnswerAgent()

        # ìƒˆë¡œìš´ í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì„± ìš”ì†Œë“¤
        self.trace_manager = TraceManagerAgent()
        self.reasoning_trace_logger = ReasoningTraceLogger()
        self.plan_revision_tool = PlanRevisionTool()
        self.state_manager = StateManager()

        # ReAct Executor Pool
        self.executor_pool = {}
        self.max_executors = 5

        # í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ í™œì„±í™” í”Œë˜ê·¸
        self.hybrid_mode_enabled = True

        self.mcp_context = {
            "role": "hybrid_orchestrator",
            "function": "hybrid_workflow_coordination",
            "agents_initialized": True,
            "hybrid_mode": True,
        }

    def process_request(self, user_input: str) -> Dict[str, Any]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ ë©”ì„œë“œ

        Args:
            user_input (str): ì‚¬ìš©ì ì…ë ¥

        Returns:
            Dict[str, Any]: ìµœì¢… ì‘ë‹µ
        """
        start_time = time.time()

        try:
            print(f"ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ ì‹œì‘: {user_input[:50]}...")

            # 1ë‹¨ê³„: Router Agent - ì˜ë„ ë¶„ì„
            print("\nğŸ“ 1ë‹¨ê³„: Router Agent - ì˜ë„ ë¶„ì„")
            router_result = self.router_agent({"user_input": user_input})
            print(f"   â”” Intent: {router_result.get('intent', 'unknown')}")

            # 2ë‹¨ê³„: Enhanced Planner Agent - í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
            print("\nğŸ“‹ 2ë‹¨ê³„: Enhanced Planner - í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½")
            planner_input = {**router_result, "user_input": user_input}
            plan_result = self.planner_agent(planner_input)

            # í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ ì²˜ë¦¬
            if (
                self.hybrid_mode_enabled
                and plan_result.get("execution_strategy") == "hybrid_react"
            ):
                return self._process_hybrid_execution(
                    plan_result, router_result, user_input, start_time
                )
            else:
                # ê¸°ì¡´ ë°©ì‹ ìœ ì§€ (í˜¸í™˜ì„±)
                return self._process_legacy_execution(
                    plan_result, router_result, user_input, start_time
                )

        except Exception as e:
            error_time = time.time() - start_time
            print(f"\nâŒ í•˜ì´ë¸Œë¦¬ë“œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì˜¤ë¥˜: {str(e)}")
            return self._create_error_response(str(e), error_time)

    def _process_hybrid_execution(
        self,
        plan_result: Dict[str, Any],
        router_result: Dict[str, Any],
        user_input: str,
        start_time: float,
    ) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í–‰ ë°©ì‹ ì²˜ë¦¬"""
        execution_steps = plan_result.get("execution_steps", [])
        dependency_graph = plan_result.get("dependency_graph", {})

        print(f"   â”” ì´ ì‹¤í–‰ ë‹¨ê³„: {len(execution_steps)}ê°œ")
        print(
            f"   â”” ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥: {len(dependency_graph.get('parallel_groups', []))}ê°œ ê·¸ë£¹"
        )

        # 3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í–‰ (Plan & Execute + ReAct)
        print("\nğŸ”„ 3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í–‰ (Plan & Execute + ReAct)")
        execution_context = {
            "user_input": user_input,
            "intent": router_result.get("intent"),
            "key_entities": router_result.get("key_entities", []),
            "execution_plan": execution_steps,
            "dependency_graph": dependency_graph,
        }

        execution_results = self._execute_hybrid_workflow(execution_context)

        # 4ë‹¨ê³„: Trace Manager - ì „ì²´ ì¶”ë¡  ê³¼ì • ë¶„ì„
        print("\nğŸ“Š 4ë‹¨ê³„: Trace Manager - ì¶”ë¡  ê³¼ì • ë¶„ì„")
        trace_analysis = self._analyze_execution_trace(
            execution_results, execution_context
        )

        # 5ë‹¨ê³„: ì‹¤íŒ¨ ë³µêµ¬ ì²˜ë¦¬ (í•„ìš”ì‹œ)
        if trace_analysis.get("final_assessment", {}).get("next_action") in [
            "retry",
            "revise",
        ]:
            print("\nğŸ”§ 5ë‹¨ê³„: ì‹¤íŒ¨ ë³µêµ¬ ì²˜ë¦¬")
            recovery_result = self._handle_failure_recovery(
                execution_results, execution_context, trace_analysis
            )
            if recovery_result.get("recovery_status") == "success":
                execution_results = recovery_result.get(
                    "recovered_results", execution_results
                )

        # 6ë‹¨ê³„: Answer Agent - ìµœì¢… ì‘ë‹µ ìƒì„±
        print("\nâœ¨ 6ë‹¨ê³„: Answer Agent - ìµœì¢… ì‘ë‹µ ìƒì„±")
        final_response = self._generate_final_response(
            execution_results, trace_analysis, execution_context
        )

        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        total_time = time.time() - start_time

        # ìµœì¢… ê²°ê³¼ êµ¬ì„±
        final_result = {
            **final_response,
            "hybrid_execution_summary": {
                "total_execution_time": f"{total_time:.2f}ì´ˆ",
                "steps_executed": len(execution_results),
                "successful_steps": len(
                    [r for r in execution_results if r.get("status") == "success"]
                ),
                "reasoning_depth": trace_analysis.get("performance_metrics", {}).get(
                    "reasoning_depth", "medium"
                ),
                "overall_confidence": trace_analysis.get("final_assessment", {}).get(
                    "confidence", 0.5
                ),
            },
            "mcp_context": {
                **self.mcp_context,
                "processing_flow": [
                    f"Router: {router_result.get('intent', 'unknown')}",
                    f"Planner: {len(execution_steps)} steps planned",
                    f"Execution: {len(execution_results)} steps executed",
                    f"Trace Analysis: {trace_analysis.get('final_assessment', {}).get('workflow_status', 'unknown')}",
                    "Answer: completed",
                ],
                "status": "success",
                "hybrid_mode_used": True,
                "total_time": total_time,
            },
        }

        print(f"\nâœ… í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ ì™„ë£Œ ({total_time:.2f}ì´ˆ)")
        return final_result

    def _process_legacy_execution(
        self,
        planner_result: Dict[str, Any],
        router_result: Dict[str, Any],
        user_input: str,
        start_time: float,
    ) -> Dict[str, Any]:
        """ê¸°ì¡´ ë°©ì‹ ì²˜ë¦¬ (í˜¸í™˜ì„± ìœ ì§€)"""
        selected_agent = planner_result.get("selected_agent", "DirectAnswer")
        print(f"   â”” Legacy Mode - Selected Agent: {selected_agent}")

        # 3. Task Management Agent ì‹¤í–‰
        agent_result = None
        if selected_agent in "TaskManagementAgent":
            print("ğŸ”§ Task Management Agent: ì‘ì—… ì²˜ë¦¬ ì¤‘...")
            agent_input = {**planner_result, "user_input": user_input}
            agent_result = self.task_management_agent(agent_input)
            print("   â”” ì‘ì—… ì²˜ë¦¬ ì™„ë£Œ")

        else:  # DirectAnswer
            print("ğŸ’¬ Direct Answer: ì§ì ‘ ì‘ë‹µ ì²˜ë¦¬ ì¤‘...")
            agent_result = {
                "agent_type": "direct",
                "answer_content": self._generate_direct_answer(user_input),
                "source_type": "direct",
                "confidence": "medium",
            }
            print("   â”” ì§ì ‘ ì‘ë‹µ ì™„ë£Œ")

        # 4. Answer Agent - ìµœì¢… ì‘ë‹µ ì •ì œ
        print("âœ¨ Answer Agent: ìµœì¢… ì‘ë‹µ ì •ì œ ì¤‘...")
        final_result = self.answer_agent(agent_result)
        print("   â”” ìµœì¢… ì‘ë‹µ ì¤€ë¹„ ì™„ë£Œ")

        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        total_time = time.time() - start_time

        # 5. MCP Context í†µí•©
        final_result["mcp_context"]["orchestrator"] = {
            **self.mcp_context,
            "processing_flow": [
                f"Router: {router_result.get('intent', 'unknown')}",
                f"Planner: {selected_agent}",
                f"Agent: {agent_result.get('agent_type', 'unknown')}",
                "Answer: completed",
            ],
            "status": "success",
            "hybrid_mode_used": False,
            "total_time": total_time,
        }

        print(f"âœ… ë ˆê±°ì‹œ ì²˜ë¦¬ ì™„ë£Œ ({total_time:.2f}ì´ˆ)")
        return final_result

    def _generate_direct_answer(self, user_input: str) -> str:
        """
        ì¼ë°˜ì ì¸ ëŒ€í™”ë¥¼ ìœ„í•œ ì§ì ‘ ì‘ë‹µ ìƒì„±

        Args:
            user_input (str): ì‚¬ìš©ì ì…ë ¥

        Returns:
            str: ì§ì ‘ ì‘ë‹µ
        """
        # ê°„ë‹¨í•œ ì¸ì‚¬ë‚˜ ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬
        user_input_lower = user_input.lower()

        if any(
            greeting in user_input_lower
            for greeting in ["ì•ˆë…•", "í•˜ì´", "í—¬ë¡œ", "ì‹œì‘"]
        ):
            return """
ì•ˆë…•í•˜ì„¸ìš”! ğŸ‘‹ 

ì €ëŠ” í´ë¼ìš°ë“œ ê±°ë²„ë„ŒìŠ¤ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì œê°€ ë„ì™€ë“œë¦´ ìˆ˜ ìˆëŠ” ê²ƒë“¤:**
â€¢ í´ë¼ìš°ë“œ ê±°ë²„ë„ŒìŠ¤ ê´€ë ¨ ì§ˆë¬¸ ë‹µë³€
â€¢ ì •ì±… ë° ì»´í”Œë¼ì´ì–¸ìŠ¤ ê°€ì´ë“œ
â€¢ ìŠ¬ë¼ì´ë“œ ë° í”„ë ˆì  í…Œì´ì…˜ ìë£Œ ìƒì„±
â€¢ ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬ ë°©ì•ˆ ì œì‹œ

ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?
"""

        elif any(
            help_word in user_input_lower
            for help_word in ["ë„ì›€", "help", "ë­ í•  ìˆ˜", "ê¸°ëŠ¥"]
        ):
            return """
**í´ë¼ìš°ë“œ ê±°ë²„ë„ŒìŠ¤ AI ì–´ì‹œìŠ¤í„´íŠ¸ ê¸°ëŠ¥ ì•ˆë‚´** ğŸ“š

ğŸ” **ì§ˆë¬¸ ì‘ë‹µ**
- í´ë¼ìš°ë“œ ê±°ë²„ë„ŒìŠ¤ ì •ì±…
- ì»´í”Œë¼ì´ì–¸ìŠ¤ ìš”êµ¬ì‚¬í•­
- ë³´ì•ˆ ê´€ë¦¬ ë°©ì•ˆ
- ëª¨ë‹ˆí„°ë§ ì „ëµ

ğŸ“Š **ìŠ¬ë¼ì´ë“œ ìƒì„±**
- í”„ë ˆì  í…Œì´ì…˜ ìë£Œ ì‘ì„±
- ê°œë… ì •ë¦¬ ìŠ¬ë¼ì´ë“œ
- ë¹„êµ ë¶„ì„ ìë£Œ

ì˜ˆì‹œ: "í´ë¼ìš°ë“œ ë³´ì•ˆ ì •ì±…ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”" ë˜ëŠ” "ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ ìŠ¬ë¼ì´ë“œ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
"""

        else:
            return """
í´ë¼ìš°ë“œ ê±°ë²„ë„ŒìŠ¤ì™€ ê´€ë ¨ëœ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì„ í•´ì£¼ì‹œë©´ ë” ë„ì›€ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´:
â€¢ "í´ë¼ìš°ë“œ ë³´ì•ˆ ì •ì±…ì´ ë¬´ì—‡ì¸ê°€ìš”?"
â€¢ "ì»´í”Œë¼ì´ì–¸ìŠ¤ ê´€ë¦¬ ë°©ì•ˆ ìŠ¬ë¼ì´ë“œ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
â€¢ "ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ ëª¨ë²” ì‚¬ë¡€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"

ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”! ğŸ˜Š
"""

    def _get_timestamp(self) -> str:
        """í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ë°˜í™˜"""
        from datetime import datetime

        return datetime.now().isoformat()

    def _execute_hybrid_workflow(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (Plan & Execute + ReAct)"""
        execution_steps = context.get("execution_plan", [])

        if not execution_steps:
            return [{"status": "error", "message": "No execution steps provided"}]

        # ê¸°ë³¸ì ìœ¼ë¡œ ìˆœì°¨ ì‹¤í–‰ (ë³‘ë ¬ ì‹¤í–‰ì€ í–¥í›„ í™•ì¥)
        execution_results = []

        for i, step in enumerate(execution_steps):
            print(f"   ğŸ“ ë‹¨ê³„ {i+1}/{len(execution_steps)}: {step['step_id']}")

            try:
                # ReAct Executor ìƒì„± ë° ì‹¤í–‰
                executor_id = f"step_{step['step_id']}"
                react_executor = self._get_or_create_executor(executor_id)

                execution_input = {"plan_step": step, "context": context}

                result = react_executor(execution_input)
                result["step_id"] = step["step_id"]
                result["step_type"] = step["step_type"]
                result["execution_method"] = "react"

                execution_results.append(result)
                print(f"   âœ… ë‹¨ê³„ ì™„ë£Œ: {step['step_id']}")

            except Exception as e:
                error_result = {
                    "step_id": step["step_id"],
                    "status": "error",
                    "error": str(e),
                    "execution_method": "react",
                }
                execution_results.append(error_result)
                print(f"   âŒ ë‹¨ê³„ ì‹¤íŒ¨: {step['step_id']} - {str(e)}")

        return execution_results

    def _get_or_create_executor(self, executor_id: str) -> ReActExecutorAgent:
        """ReAct Executor ìƒì„± ë˜ëŠ” ê¸°ì¡´ ê²ƒ ë°˜í™˜"""
        if executor_id not in self.executor_pool:
            if len(self.executor_pool) >= self.max_executors:
                # í’€ì´ ê°€ë“ ì°¬ ê²½ìš° ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ ì œê±°
                oldest_key = next(iter(self.executor_pool))
                del self.executor_pool[oldest_key]

            self.executor_pool[executor_id] = ReActExecutorAgent(executor_id)

        return self.executor_pool[executor_id]

    def _analyze_execution_trace(
        self, execution_results: List[Dict[str, Any]], context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì „ì²´ ì‹¤í–‰ ì¶”ì  ë¶„ì„"""
        trace_input = {
            "execution_results": execution_results,
            "failed_steps": [
                r
                for r in execution_results
                if r.get("status") not in ["success", "partial_success"]
            ],
            "context": context,
        }

        return self.trace_manager(trace_input)

    def _handle_failure_recovery(
        self,
        execution_results: List[Dict[str, Any]],
        context: Dict[str, Any],
        trace_analysis: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ì‹¤íŒ¨ ë³µêµ¬ ì²˜ë¦¬"""
        failed_steps = [
            r
            for r in execution_results
            if r.get("status") not in ["success", "partial_success"]
        ]

        if not failed_steps:
            return {"recovery_status": "no_recovery_needed"}

        # ê¸°ë³¸ ë³µêµ¬: ë‹¨ìˆœíˆ ì¬ì‹œë„ ê¶Œì¥
        return {
            "recovery_status": "completed",
            "recovery_strategy": "retry_recommended",
            "recovered_results": execution_results,
        }

    def _generate_final_response(
        self,
        execution_results: List[Dict[str, Any]],
        trace_analysis: Dict[str, Any],
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ìµœì¢… ì‘ë‹µ ìƒì„±"""
        # ì„±ê³µí•œ ê²°ê³¼ë“¤ì—ì„œ ìµœì¢… ë‹µë³€ ì¶”ì¶œ
        successful_results = [
            r for r in execution_results if r.get("status") == "success"
        ]

        if successful_results:
            latest_result = successful_results[-1]
            answer_content = latest_result.get("final_result", "")
        else:
            # ë¶€ë¶„ ì„±ê³µì´ë¼ë„ ì‚¬ìš©
            partial_results = [
                r for r in execution_results if r.get("status") == "partial_success"
            ]
            if partial_results:
                answer_content = partial_results[-1].get("final_result", "")
            else:
                answer_content = "ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # Answer Agent ì…ë ¥ êµ¬ì„±
        answer_input = {
            "agent_type": "hybrid_execution",
            "answer_content": answer_content,
            "execution_results": execution_results,
            "reasoning_trace": self.reasoning_trace_logger.get_global_trace(),
            "trace_summary": trace_analysis.get("trace_summary", {}),
            "overall_confidence": trace_analysis.get("final_assessment", {}).get(
                "confidence", 0.5
            ),
            "source_type": "hybrid_react",
        }

        return self.answer_agent(answer_input)

    def _create_error_response(
        self, error_message: str, execution_time: float
    ) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return {
            "final_answer": f"ì‹œìŠ¤í…œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_message}\n\ní•˜ì´ë¸Œë¦¬ë“œ AI ì‹œìŠ¤í…œì´ ë³µêµ¬ë¥¼ ì‹œë„í–ˆì§€ë§Œ ì™„ì „í•œ ì²˜ë¦¬ê°€ ì–´ë ¤ì› ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
            "timestamp": self._get_timestamp(),
            "hybrid_execution_summary": {
                "total_execution_time": f"{execution_time:.2f}ì´ˆ",
                "steps_executed": 0,
                "successful_steps": 0,
                "reasoning_depth": "error",
                "overall_confidence": 0.0,
            },
            "mcp_context": {
                **self.mcp_context,
                "status": "error",
                "error_message": error_message,
                "hybrid_mode_used": False,
                "total_time": execution_time,
            },
        }

    def get_system_status(self) -> Dict[str, Any]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸

        Returns:
            Dict[str, Any]: ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´
        """
        return {
            "orchestrator": "hybrid_running",
            "agents": {
                "router": "initialized",
                "enhanced_planner": "initialized",
                "task_management": "legacy_support",
                "answer": "enhanced",
                "trace_manager": "initialized",
            },
            "react_executors": {
                "pool_size": len(self.executor_pool),
                "max_executors": self.max_executors,
                "active_executors": list(self.executor_pool.keys()),
            },
            "tools": {
                "reasoning_trace_logger": "active",
                "plan_revision_tool": "active",
                "state_manager": "active",
                "rag_retriever": "available",
                "slide_formatter": "available",
                "report_summary": "available",
            },
            "hybrid_features": {
                "parallel_execution": False,  # í–¥í›„ êµ¬í˜„
                "react_reasoning": True,
                "failure_recovery": True,
                "trace_analysis": True,
                "hybrid_mode_enabled": self.hybrid_mode_enabled,
            },
            "mcp_context": self.mcp_context,
        }

    def set_hybrid_mode(self, enabled: bool):
        """í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ í™œì„±í™”/ë¹„í™œì„±í™”"""
        self.hybrid_mode_enabled = enabled
        self.mcp_context["hybrid_mode"] = enabled
        print(f"ğŸ”§ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ: {'í™œì„±í™”' if enabled else 'ë¹„í™œì„±í™”'}")

    def clear_execution_state(self):
        """ì‹¤í–‰ ìƒíƒœ ì´ˆê¸°í™”"""
        self.executor_pool.clear()
        self.reasoning_trace_logger.clear_traces()
        self.plan_revision_tool.clear_history()
        self.state_manager.clear_all_states()
        print("ğŸ§¹ í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í–‰ ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ")
