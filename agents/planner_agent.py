import json
import re
from typing import Dict, Any, List
from datetime import datetime

from core import BaseAgent


class PlannerAgent(BaseAgent):
    """
    Planner Agent
    Router Agentì˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì–´ë–¤ ìž‘ì—…ì„ ìˆ˜í–‰í• ì§€ ê²°ì •
    Task Management Agentì— ì „ë‹¬í•  ìž‘ì—… íƒ€ìž… ê²°ì •
    """

    def __init__(self):
        super().__init__("PlannerAgent")
        self.mcp_context = {"role": "planner", "function": "task_planning"}

    def _create_prompt(self, inputs: Dict[str, Any]) -> str:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            inputs (Dict[str, Any]): Router Agent ê²°ê³¼ í¬í•¨

        Returns:
            str: LLMìš© í”„ë¡¬í”„íŠ¸
        """
        # Router Agent ê²°ê³¼ ì¶”ì¶œ
        intent = inputs.get("intent", "general")
        confidence = inputs.get("confidence", 0.0)
        key_entities = inputs.get("key_entities", [])
        user_input = inputs.get("user_input", "")

        # í˜„ìž¬ ì˜ë„ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì— ì €ìž¥ (ê²€ì¦ ì‹œ ì‚¬ìš©)
        self._current_intent = intent

        prompt = f"""
ë‹¹ì‹ ì€ í´ë¼ìš°ë“œ ê±°ë²„ë„ŒìŠ¤ AI ì‹œìŠ¤í…œì˜ Enhanced Planner Agentìž…ë‹ˆë‹¤.
Router Agentì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•´ì•¼ í•©ë‹ˆë‹¤.

**Router Agent ë¶„ì„ ê²°ê³¼:**
- Intent: {intent}
- Confidence: {confidence}
- Key Entities: {key_entities}
- Original Input: {user_input}

**ì¤‘ìš”: ì˜ë„ë³„ ì‹¤í–‰ ê³„íš ê°€ì´ë“œë¼ì¸:**

1. **intentê°€ "question" ë˜ëŠ” "general"ì¸ ê²½ìš°:**
   - ìŠ¬ë¼ì´ë“œ ìƒì„± ê´€ë ¨ ë‹¨ê³„(drafting, generating)ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ
   - slide_draft, slide_generator ë„êµ¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
   - data_collectionê³¼ analysis ë‹¨ê³„ë§Œ ì‚¬ìš©
   - ê°„ë‹¨í•œ ì§ˆë¬¸ ë‹µë³€ì— ì§‘ì¤‘

2. **intentê°€ "slide_generation"ì¸ ê²½ìš°:**
   - ì „ì²´ ìŠ¬ë¼ì´ë“œ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
   - data_collection â†’ analysis â†’ drafting â†’ generating ìˆœì„œ
   - ëª¨ë“  ìŠ¬ë¼ì´ë“œ ê´€ë ¨ ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥

**í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í–‰ ì „ëžµ:**
1. ì „ì²´ì ì¸ coarse-grained plan ìˆ˜ë¦½
2. ê° ë‹¨ê³„ë³„ë¡œ ReAct Executor í• ë‹¹
3. ë³‘ë ¬/ìˆœì°¨ ì‹¤í–‰ ê²°ì •
4. ì‹¤íŒ¨ ë³µêµ¬ ì „ëžµ í¬í•¨

**ì‹¤í–‰ ë‹¨ê³„ ìœ í˜•:**
- "data_collection": RAG ê¸°ë°˜ ì •ë³´ ìˆ˜ì§‘
- "analysis": ìˆ˜ì§‘ëœ ë°ì´í„° ë¶„ì„
- "drafting": ìŠ¬ë¼ì´ë“œ ì´ˆì•ˆ ìž‘ì„± (slide_generation intentì—ë§Œ ì‚¬ìš©)
- "validation": ê²°ê³¼ ê²€ì¦
- "generating": ìµœì¢… ìŠ¬ë¼ì´ë“œ ê²°ê³¼ë¬¼ ìƒì„± (slide_generation intentì—ë§Œ ì‚¬ìš©)

**ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:**
- "rag_retriever": RAG ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ (MCP ë„êµ¬ëª…: search_documents)
- "slide_draft": ìŠ¬ë¼ì´ë“œ ì´ˆì•ˆ ìƒì„± (MCP ë„êµ¬ëª…: create_slide_draft) - slide_generation intentì—ë§Œ ì‚¬ìš©
- "slide_generator": ìµœì¢… ìŠ¬ë¼ì´ë“œ ìƒì„± (LangChain Tool) - slide_generation intentì—ë§Œ ì‚¬ìš©
- "report_summary": ë³´ê³ ì„œ ìš”ì•½ (MCP ë„êµ¬ëª…: summarize_report)
- "get_tool_status": ë„êµ¬ ìƒíƒœ í™•ì¸

**ì˜ë„ë³„ ê¶Œìž¥ ì‹¤í–‰ ê³„íš:**

Intentê°€ "question" ë˜ëŠ” "general"ì¸ ê²½ìš°:
- data_collection: ["rag_retriever"]
- analysis: ["rag_retriever", "report_summary"]

Intentê°€ "slide_generation"ì¸ ê²½ìš°:
- data_collection: ["rag_retriever"]
- analysis: ["rag_retriever", "report_summary"]
- drafting: ["slide_draft"]
- validation: ["rag_retriever"]
- generating: ["slide_generator"]

**ì¶œë ¥ í˜•ì‹ (JSON):**
{{
    "execution_strategy": "hybrid_react",
    "overall_plan": {{
        "intent_type": "{intent}",
        "complexity": "simple|medium|complex",
        "estimated_steps": 3,
        "parallel_execution": true/false
    }},
    "execution_steps": [
        {{
            "step_id": "step_1",
            "step_type": "data_collection|analysis|drafting|validation|generating",
            "description": "ë‹¨ê³„ ì„¤ëª…",
            "required_tools": ["rag_retriever", "slide_generator"],
            "depends_on": [],
            "priority": "high|medium|low",
            "timeout": 30,
            "retry_enabled": true
        }}
    ],
    "failure_recovery": {{
        "auto_retry": true,
        "max_retries": 2,
        "fallback_strategy": "simplify|alternative_path|manual_intervention"
    }},
    "success_criteria": {{
        "min_step_success_rate": 0.8,
        "overall_confidence_threshold": 0.7,
        "max_execution_time": 300
    }},
    "mcp_context": {{"role": "enhanced_planner", "status": "success"}}
}}

ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
"""
        return prompt

    def postprocess(self, outputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        Enhanced Planner Agent ì¶œë ¥ í›„ì²˜ë¦¬

        Args:
            outputs (Dict[str, Any]): LLM ì‘ë‹µ

        Returns:
            Dict[str, Any]: í›„ì²˜ë¦¬ëœ ê²°ê³¼
        """
        try:
            # LLM ì‘ë‹µì—ì„œ JSON íŒŒì‹±
            content = outputs.content if hasattr(outputs, "content") else str(outputs)

            # JSON ë¶€ë¶„ ì¶”ì¶œ
            json_match = re.search(r"\{.*\}", content, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())

                # ì‹¤í–‰ ê³„íš ê²€ì¦ ë° ë³´ì™„
                execution_steps = result.get("execution_steps", [])
                validated_steps = self._validate_execution_steps(execution_steps)
                result["execution_steps"] = validated_steps

                # ì˜ì¡´ì„± ì²´í¬
                dependency_graph = self._build_dependency_graph(validated_steps)
                result["dependency_graph"] = dependency_graph

                # MCP context ì—…ë°ì´íŠ¸
                result["mcp_context"] = {
                    **self.mcp_context,
                    "status": "success",
                    "execution_strategy": result.get(
                        "execution_strategy", "hybrid_react"
                    ),
                    "total_steps": len(validated_steps),
                    "planning_timestamp": self._get_timestamp(),
                }

                return result
            else:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
                return self._create_fallback_plan()

        except Exception as e:
            return self._create_error_plan(str(e))

    def _validate_execution_steps(
        self, steps: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ì‹¤í–‰ ë‹¨ê³„ ê²€ì¦ ë° ë³´ì™„"""
        validated_steps = []

        # ë„êµ¬ ì´ë¦„ ë§¤í•‘ (ìž˜ëª»ëœ ë„êµ¬ëª… â†’ ì˜¬ë°”ë¥¸ ë„êµ¬ëª…)
        tool_mapping = {
            "search_documents": "rag_retriever",
            "text_analyzer": "rag_retriever",
            "slide_formatter": "slide_draft",
            "validator": "rag_retriever",
            "summarize_report": "report_summary",
        }

        # ë‹¨ê³„ ìœ í˜•ë³„ ê¸°ë³¸ ë„êµ¬
        default_tools_by_type = {
            "data_collection": ["rag_retriever"],
            "analysis": ["rag_retriever"],
            "drafting": ["slide_draft"],
            "validation": ["rag_retriever"],
            "generating": ["slide_generator"],
        }

        # í˜„ìž¬ ì²˜ë¦¬ ì¤‘ì¸ ì˜ë„ í™•ì¸ (mcp_contextì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        current_intent = getattr(self, "_current_intent", "general")

        for i, step in enumerate(steps):
            # ê¸°ë³¸ í•„ë“œ ì„¤ì •
            step_type = step.get("step_type", "general")
            required_tools = step.get("required_tools", [])

            # ì˜ë„ì— ë”°ë¥¸ ë‹¨ê³„ í•„í„°ë§
            if current_intent in ["question", "general"]:
                # ì¼ë°˜ ì§ˆë¬¸ì¸ ê²½ìš° ìŠ¬ë¼ì´ë“œ ìƒì„± ê´€ë ¨ ë‹¨ê³„ ì œì™¸
                if step_type in ["drafting", "generating"]:
                    print(f"   ðŸš« ì¼ë°˜ ì§ˆë¬¸ì´ë¯€ë¡œ ìŠ¬ë¼ì´ë“œ ìƒì„± ë‹¨ê³„ ì œì™¸: {step_type}")
                    continue

                # ìŠ¬ë¼ì´ë“œ ìƒì„± ë„êµ¬ ì œì™¸
                required_tools = [
                    tool
                    for tool in required_tools
                    if tool not in ["slide_draft", "slide_generator"]
                ]

            # ë„êµ¬ ì´ë¦„ ê²€ì¦ ë° ë§¤í•‘
            validated_tools = []
            for tool in required_tools:
                if tool in tool_mapping:
                    validated_tools.append(tool_mapping[tool])
                elif tool in [
                    "rag_retriever",
                    "slide_draft",
                    "slide_generator",
                    "report_summary",
                    "get_tool_status",
                ]:
                    # ì¼ë°˜ ì§ˆë¬¸ì¸ ê²½ìš° ìŠ¬ë¼ì´ë“œ ìƒì„± ë„êµ¬ ì œì™¸
                    if current_intent in ["question", "general"] and tool in [
                        "slide_draft",
                        "slide_generator",
                    ]:
                        continue
                    validated_tools.append(tool)
                else:
                    # ì•Œë ¤ì§€ì§€ ì•Šì€ ë„êµ¬ëŠ” ë‹¨ê³„ ìœ í˜•ì— ë”°ë¼ ê¸°ë³¸ ë„êµ¬ë¡œ ëŒ€ì²´
                    if step_type in default_tools_by_type:
                        default_tools = default_tools_by_type[step_type]
                        # ì¼ë°˜ ì§ˆë¬¸ì¸ ê²½ìš° ìŠ¬ë¼ì´ë“œ ìƒì„± ë„êµ¬ ì œì™¸
                        if current_intent in ["question", "general"]:
                            default_tools = [
                                tool
                                for tool in default_tools
                                if tool not in ["slide_draft", "slide_generator"]
                            ]
                        validated_tools.extend(default_tools)

            # ë„êµ¬ê°€ ì—†ëŠ” ê²½ìš° ë‹¨ê³„ ìœ í˜•ì— ë”°ë¼ ê¸°ë³¸ ë„êµ¬ ì„¤ì •
            if not validated_tools and step_type in default_tools_by_type:
                default_tools = default_tools_by_type[step_type]
                # ì¼ë°˜ ì§ˆë¬¸ì¸ ê²½ìš° ìŠ¬ë¼ì´ë“œ ìƒì„± ë„êµ¬ ì œì™¸
                if current_intent in ["question", "general"]:
                    default_tools = [
                        tool
                        for tool in default_tools
                        if tool not in ["slide_draft", "slide_generator"]
                    ]
                validated_tools = default_tools

            # ìµœì¢… ê²€ì¦ëœ ë‹¨ê³„
            # ë¹ˆ ë„êµ¬ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê¸°ë³¸ ë„êµ¬ ì„¤ì •
            if not validated_tools:
                validated_tools = ["rag_retriever"]  # ìµœì†Œí•œ ê¸°ë³¸ ë„êµ¬ëŠ” ì„¤ì •

            validated_step = {
                "step_id": step.get("step_id", f"step_{i+1}"),
                "step_type": step_type,
                "description": step.get("description", f"Execute step {i+1}"),
                "required_tools": validated_tools,
                "depends_on": step.get("depends_on", []),
                "priority": step.get("priority", "medium"),
                "timeout": step.get("timeout", 60),
                "retry_enabled": step.get("retry_enabled", True),
                "max_retries": step.get("max_retries", 2),
            }
            validated_steps.append(validated_step)

        return validated_steps

    def _build_dependency_graph(self, steps: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì˜ì¡´ì„± ê·¸ëž˜í”„ êµ¬ì„±"""
        graph = {
            "nodes": [step["step_id"] for step in steps],
            "edges": [],
            "parallel_groups": [],
            "sequential_order": [],
        }

        # ì˜ì¡´ì„± ì—£ì§€ ìƒì„±
        for step in steps:
            step_id = step["step_id"]
            depends_on = step.get("depends_on", [])

            for dependency in depends_on:
                graph["edges"].append({"from": dependency, "to": step_id})

        # ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ê·¸ë£¹ ì‹ë³„
        independent_steps = [
            step["step_id"] for step in steps if not step.get("depends_on", [])
        ]

        if len(independent_steps) > 1:
            graph["parallel_groups"].append(independent_steps)

        # ìˆœì°¨ ì‹¤í–‰ ìˆœì„œ ê²°ì •
        remaining_steps = [step["step_id"] for step in steps]
        execution_order = []

        while remaining_steps:
            # ì˜ì¡´ì„±ì´ í•´ê²°ëœ ë‹¨ê³„ë“¤ ì°¾ê¸°
            ready_steps = []
            for step_id in remaining_steps:
                step = next(s for s in steps if s["step_id"] == step_id)
                dependencies = step.get("depends_on", [])

                if all(dep in execution_order for dep in dependencies):
                    ready_steps.append(step_id)

            if ready_steps:
                execution_order.extend(ready_steps)
                for step_id in ready_steps:
                    remaining_steps.remove(step_id)
            else:
                # ìˆœí™˜ ì˜ì¡´ì„±ì´ë‚˜ ì˜¤ë¥˜ ìƒí™©
                execution_order.extend(remaining_steps)
                break

        graph["sequential_order"] = execution_order

        return graph

    def _create_fallback_plan(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ëŒ€ì²´ ê³„íš ìƒì„±"""
        current_intent = getattr(self, "_current_intent", "general")

        # ì˜ë„ì— ë”°ë¥¸ ê¸°ë³¸ ê³„íš ìƒì„±
        if current_intent == "slide_generation":
            execution_steps = [
                {
                    "step_id": "fallback_data_collection",
                    "step_type": "data_collection",
                    "description": "ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘",
                    "required_tools": ["rag_retriever"],
                    "depends_on": [],
                    "priority": "medium",
                    "timeout": 60,
                    "retry_enabled": True,
                },
                {
                    "step_id": "fallback_slide_generation",
                    "step_type": "generating",
                    "description": "ê¸°ë³¸ ìŠ¬ë¼ì´ë“œ ìƒì„±",
                    "required_tools": ["slide_generator"],
                    "depends_on": ["fallback_data_collection"],
                    "priority": "medium",
                    "timeout": 120,
                    "retry_enabled": True,
                },
            ]
        else:
            # ì¼ë°˜ ì§ˆë¬¸ì¸ ê²½ìš° ìŠ¬ë¼ì´ë“œ ìƒì„± ë‹¨ê³„ ì œì™¸
            execution_steps = [
                {
                    "step_id": "fallback_step",
                    "step_type": "data_collection",
                    "description": "ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘ ë° ë¶„ì„",
                    "required_tools": ["rag_retriever"],
                    "depends_on": [],
                    "priority": "medium",
                    "timeout": 60,
                    "retry_enabled": True,
                }
            ]

        return {
            "execution_strategy": "hybrid_react",
            "overall_plan": {
                "intent_type": current_intent,
                "complexity": "simple",
                "estimated_steps": len(execution_steps),
                "parallel_execution": False,
            },
            "execution_steps": execution_steps,
            "failure_recovery": {
                "auto_retry": True,
                "max_retries": 1,
                "fallback_strategy": "manual_intervention",
            },
            "success_criteria": {
                "min_step_success_rate": 0.5,
                "overall_confidence_threshold": 0.5,
                "max_execution_time": 120,
            },
            "dependency_graph": {
                "nodes": ["fallback_step"],
                "edges": [],
                "parallel_groups": [],
                "sequential_order": ["fallback_step"],
            },
            "mcp_context": {
                **self.mcp_context,
                "status": "fallback",
                "message": "JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ê¸°ë³¸ ê³„íš ì ìš©",
            },
        }

    def _create_error_plan(self, error_message: str) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ìƒí™©ì„ ìœ„í•œ ê³„íš ìƒì„±"""
        return {
            "execution_strategy": "error_recovery",
            "overall_plan": {
                "intent_type": "error",
                "complexity": "simple",
                "estimated_steps": 1,
                "parallel_execution": False,
            },
            "execution_steps": [
                {
                    "step_id": "error_handling",
                    "step_type": "validation",
                    "description": f"Handle planning error: {error_message}",
                    "required_tools": ["reasoning_trace_logger"],
                    "depends_on": [],
                    "priority": "high",
                    "timeout": 30,
                    "retry_enabled": False,
                }
            ],
            "failure_recovery": {
                "auto_retry": False,
                "max_retries": 0,
                "fallback_strategy": "manual_intervention",
            },
            "success_criteria": {
                "min_step_success_rate": 1.0,
                "overall_confidence_threshold": 0.3,
                "max_execution_time": 60,
            },
            "mcp_context": {
                **self.mcp_context,
                "status": "error",
                "message": error_message,
            },
        }

    def _get_timestamp(self) -> str:
        """í˜„ìž¬ íƒ€ìž„ìŠ¤íƒ¬í”„ ë°˜í™˜"""
        return datetime.now().isoformat()
